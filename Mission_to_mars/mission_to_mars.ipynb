{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA's Mars 2020 Rover Closer to Getting Its Name\n",
      "155 students from across the U.S. have been chosen as semifinalists in NASA's essay contest to name the Mars 2020 rover, and see it launch from Cape Canaveral this July.\n"
     ]
    }
   ],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "#parse page\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Extract article title and paragraph text\n",
    "results = soup.find('div', class_='list_text')\n",
    "news_title = results.find('div', class_='content_title').text\n",
    "news_teaser = results.find('div', class_ ='article_teaser_body').text\n",
    "print(news_title)\n",
    "print(news_teaser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA14106_hires.jpg\n"
     ]
    }
   ],
   "source": [
    "#get image\n",
    "url2 = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(url2)\n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "time.sleep(10)\n",
    "\n",
    "# Go to 'more info'\n",
    "browser.click_link_by_partial_text('more info')\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "html = browser.html\n",
    "image_soup = bs(html, 'html.parser')\n",
    "\n",
    "# Scrape the URL\n",
    "img_url = image_soup.find('figure', class_='lede').a['href']\n",
    "featured_image_url = f'https://www.jpl.nasa.gov{img_url}'\n",
    "print(featured_image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "InSight sol 408 (2020-01-19) low -97.1ºC (-142.7ºF) high -16.0ºC (3.1ºF)\n",
      "winds from the SSW at 5.2 m/s (11.6 mph) gusting to 20.7 m/s (46.3 mph)\n",
      "pressure at 6.40 hPapic.twitter.com/tIqoEyK2Uk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url3 = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(url3)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# results = soup.find('div', class_='stream')\n",
    "\n",
    "\n",
    "# mars_weather = results.find('div', class_='js-tweet-text-container').text \n",
    "# print(mars_weather)\n",
    "mars_tweets = soup.find_all('div', class_='js-tweet-text-container')\n",
    "\n",
    "    for tweet in mars_tweets:\n",
    "        mars_weather = tweet.find('p').text \n",
    "        if 'sol' and 'pressure' in mars_weather:\n",
    "            break\n",
    "            print(mars_weather)\n",
    "        else: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = \"https://space-facts.com/mars/\"\n",
    "browser.visit(url4)\n",
    "html = browser.html\n",
    "\n",
    "# Use Pandas to scrape the table to HTML\n",
    "dfs = pd.read_html(url4)\n",
    "mars_facts = dfs[1]\n",
    "mars_facts\n",
    "\n",
    "# # Rename columns\n",
    "# mars_facts.columns = ['Description','Mars']\n",
    "\n",
    "mars_facts.drop(['Earth'], axis=1, inplace=True)\n",
    "mars_facts.rename(columns={'Mars - Earth Comparison':'Description', 'Mars':'Value'}, inplace=True)\n",
    "mars_facts\n",
    "\n",
    "# Reset Index to be description\n",
    "mars_facts.set_index('Description', inplace=True)\n",
    "mars_facts\n",
    "\n",
    "mars_facts.to_html('mars_facts.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere ', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'title': 'Schiaparelli Hemisphere ', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'title': 'Syrtis Major Hemisphere ', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, {'title': 'Valles Marineris Hemisphere ', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "url5 = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(url5)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "\n",
    "# Create dictionary to store titles & links to images\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Retrieve all elements that contain image information\n",
    "results = soup.find(\"div\", class_ = \"result-list\" )\n",
    "hemispheres = results.find_all(\"div\", class_=\"item\")\n",
    "\n",
    "# Iterate through each image\n",
    "for hemisphere in hemispheres:\n",
    "    title = hemisphere.find(\"h3\").text\n",
    "    title = title.replace(\"Enhanced\", \"\")\n",
    "    end_link = hemisphere.find(\"a\")[\"href\"]\n",
    "    image_link = \"https://astrogeology.usgs.gov/\" + end_link    \n",
    "    browser.visit(image_link)\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    downloads = soup.find(\"div\", class_=\"downloads\")\n",
    "    image_url = downloads.find(\"a\")[\"href\"]\n",
    "    hemisphere_image_urls.append({\"title\": title, \"img_url\": image_url})\n",
    "\n",
    "# Print image title and url\n",
    "print(hemisphere_image_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
